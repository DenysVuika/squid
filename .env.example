# Database configuration
DATABASE_URL=postgresql://localhost/mydb

# ============================================================
# OpenAI API Configuration (for 'ask' command)
# ============================================================
# Used with LM Studio or OpenAI API
API_URL=http://127.0.0.1:1234/v1
API_MODEL=local-model
API_KEY=not-needed

# For OpenAI (instead of LM Studio):
# API_URL=https://api.openai.com/v1
# API_MODEL=gpt-4
# API_KEY=sk-your-api-key-here

# ============================================================
# Local Models (for 'ask-local' command)
# ============================================================
# No configuration needed! Models are loaded directly from
# HuggingFace. Examples of tested working models:
#
# Small & Fast:
#   cargo run -- ask-local -m "Qwen/Qwen2.5-0.5B-Instruct" "question"
#   cargo run -- ask-local -m "TinyLlama/TinyLlama-1.1B-Chat-v1.0" "question"
#
# Balanced:
#   cargo run -- ask-local -m "Qwen/Qwen2.5-1.5B-Instruct" "question"
#
# High Quality:
#   cargo run -- ask-local -m "microsoft/Phi-3-mini-4k-instruct" "question"
#
# Note: Check https://ericlbuehler.github.io/mistral.rs/supported_models.html
# for full list of compatible models
